train-subset: train_st,train_gtranslate_st
valid-subset: dev_st,dev_gtranslate_st

max-epoch: 50
max-update: 300000

num-workers: 8
patience: 10
no-progress-bar: True
log-interval: 100
seed: 1
report-accuracy: True

load-pretrained-encoder-from: /home/liuxiaowen/st/checkpoints/librispeech/asr/0511_2119_valid_train_ctc_baseline/avg_10_checkpoint.pt
load-pretrained-decoder-from: /home/liuxiaowen/st/checkpoints/OpenSubtitles/mt/wmt_share10k_0514_1143_lcrm_tok_train_baseline/avg_10_checkpoint.pt
#load-pretrained-decoder-from: /home/liuxiaowen/st/checkpoints/librispeech/asr/0511_2119_valid_train_ctc_baseline/avg_10_checkpoint.pt

arch: s2t_transformer_s
share-decoder-input-output-embed: True
optimizer: adam
clip-norm: 10.0
lr-scheduler: inverse_sqrt
warmup-init-lr: 1e-7
warmup-updates: 10000
lr: 2e-3
#adam_betas: (0.9,0.98)

ctc-weight: 0.3
criterion: label_smoothed_cross_entropy_with_ctc
label_smoothing: 0.1

conv-kernel-sizes: 5,5
conv-channels: 1024
dropout: 0.1
activation-fn: relu
encoder-embed-dim: 256
encoder-ffn-embed-dim: 2048
encoder-layers: 12
decoder-layers: 6
encoder-attention-heads: 4

decoder-embed-dim: 256
decoder-ffn-embed-dim: 2048
decoder-attention-heads: 4
attention-dropout: 0.1
activation-dropout: 0.1
